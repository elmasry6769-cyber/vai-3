# === AI Video Generator (Stable Video Diffusion) ===
from diffusers import StableVideoDiffusionPipeline
import torch
from PIL import Image
import imageio
import os

def generate_video(image_path, output_name="generated_video.mp4", frames_count=25, fps=6):
    """
    ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ Ù…Ù† ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Stable Video Diffusion
    """
    print("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")

    pipe = StableVideoDiffusionPipeline.from_pretrained(
        "stabilityai/stable-video-diffusion-img2vid-xt",
        torch_dtype=torch.float16,
        variant="fp16"
    ).to("cuda")

    print("ğŸ–¼ï¸ Ø¬Ø§Ø±ÙŠ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©...")
    image = Image.open(image_path)

    print("ğŸ¬ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
    frames = pipe(image, num_frames=frames_count).frames[0]

    print("ğŸ’¾ Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
    imageio.mimsave(output_name, frames, fps=fps)

    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­! Ø§Ù„Ù…Ù„Ù: {output_name}")

if __name__ == "__main__":
    # Ø§Ø³ØªØ¨Ø¯Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ ÙÙŠ Ù…Ø´Ø±ÙˆØ¹Ùƒ
    image_path = "your_image.jpg"
    if os.path.exists(image_path):
        generate_video(image_path)
    else:
        print("âš ï¸ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©! Ø¶Ø¹ ØµÙˆØ±Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø³Ù… your_image.jpg")
